{"cells":[{"cell_type":"code","source":["# IMPORTS\n\nimport pandas as pd\nimport numpy as np\nimport json\nimport inspect\nimport networkx as nx"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/networkx/classes/graph.py:23: DeprecationWarning: Using or importing the ABCs from &#39;collections&#39; instead of from &#39;collections.abc&#39; is deprecated, and in 3.8 it will stop working\n  from collections import Mapping\n</div>"]}}],"execution_count":1},{"cell_type":"code","source":["# Serealize result to json\nclass ObjectEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if hasattr(obj, \"to_json\"):\n            return self.default(obj.to_json())\n        elif hasattr(obj, \"__dict__\"):\n            d = dict(\n                (key, value)\n                for key, value in inspect.getmembers(obj)\n                if not key.startswith(\"__\")\n                and not inspect.isabstract(value)\n                and not inspect.isbuiltin(value)\n                and not inspect.isfunction(value)\n                and not inspect.isgenerator(value)\n                and not inspect.isgeneratorfunction(value)\n                and not inspect.ismethod(value)\n                and not inspect.ismethoddescriptor(value)\n                and not inspect.isroutine(value)\n            )\n            return self.default(d)\n        return obj"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["# GLOBAL FUNCTIONS\n\n# Read data with given table.table_name as parquet file\ndef get_data(table):  \n    df_pqt = spark.table(table['name'])\n    return df_pqt\n  \n# Read schema_discovery json object located in given path              \ndef get_schema_discovery(schema_discovery_file_location): \n    spark.conf.set(\"fs.azure.account.key.homecredittest01.blob.core.windows.net\", dbutils.secrets.get(scope = \"blobs\", key = \"hcaccesskey\"))\n    dbutils.fs.cp(schema_discovery_file_location, \"/dbfs/tmp/schema_discovery.json\")\n\n    with open(\"/dbfs/tmp/schema_discovery_with_entities_and_dependencies.json\", 'r', encoding='utf-8') as f:\n        schema_discovery = json.load(f)\n        \n    return schema_discovery"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["# Read schema_discovery object    \nschema_discovery_file_location = \"wasbs://hc-test-data-01@homecredittest01.blob.core.windows.net/hc-test-01/schema_discovery.json\"\nschema_discovery = get_schema_discovery(schema_discovery_file_location)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["class GAN:\n    data = None\n    def train(self, data):\n        self.data = data        \n    def predict(self):\n        return self.data\n      \nclass CGAN:\n    data = None\n    def train(self, data, cond_data):\n        self.data = data        \n    def predict(self, cond_data):\n        return self.data\n\ndef sort_table_by_degree(schema_discovery):\n    g = nx.DiGraph()\n    table_dep_dict = {}\n    for dep in schema_discovery['dependencies']:\n        table_name_1 = dep['left']['tableName']\n        table_name_2 = dep['right']['tableName']\n        col_name_1 = dep['left']['columnName']\n        col_name_2 = dep['right']['columnName']\n        relationship_col_1 = dep['left']['relationshipType']\n        relationship_col_2 = dep['right']['relationshipType']\n        \n        if ((relationship_col_1 == 'Equal') & (relationship_col_2 == 'Equal') | (relationship_col_1 == 'Overlap') & (relationship_col_2 == 'Overlap')):\n            g.add_edge((table_name_1, col_name_1), (table_name_2, col_name_2))\n            g.add_edge((table_name_2, col_name_2), (table_name_1, col_name_1))\n        \n        elif (relationship_col_1 == 'Contains') & (relationship_col_2 == 'Contained'):\n            g.add_edge((table_name_1, col_name_1), (table_name_2, col_name_2))\n            if (table_name_2, col_name_2) not in table_dep_dict:\n                table_dep_dict[(table_name_2, col_name_2)] = []               \n            table_dep_dict[(table_name_2, col_name_2)].append((table_name_1, col_name_1))\n        \n        elif (relationship_col_1 == 'Contained') & (relationship_col_2 == 'Contains'):\n            g.add_edge((table_name_2, col_name_2), (table_name_1, col_name_1))\n            if (table_name_1, col_name_1) not in table_dep_dict:\n                table_dep_dict[(table_name_1, col_name_1)] = []               \n            table_dep_dict[(table_name_1, col_name_1)].append((table_name_2, col_name_2))\n        \n        else:\n            print('NOT FOUND ' + table_name_1 + ' ' + table_name_2 + ' ' + relationship_col_1 + ' ' + relationship_col_2)\n            \n    in_degree_dict = {k: v for k, v in sorted(dict(g.in_degree).items(), key=lambda item: item[1])}\n    return in_degree_dict, table_dep_dict      \n  \ndef get_table_by_name(schema_discovery, table_name):\n    for table in schema_discovery['tables']:\n        if table['name'] == table_name:\n            return table\n    return None\n  \ndef get_entity_data(data, entity):\n    col_list = [col['name'] for col in entity['columns']]\n    return data.select(col_lost)\n  \ndef train_without_condition(table): \n    data = get_data(table)\n    model = GAN()\n    model.train(data)\n    return model\n  \ndef train_with_condition(schema_discovery, table_name, col_name, table_dep_dict):\n    all_cond_data = []\n    table = get_table_by_name(schema_discovery, table_name)\n    data = get_data(table)\n    for cond_table_name in table_dep_dict[(table_name, col_name)]:\n        cond_table = get_table_by_name(schema_discovery, cond_table_name)\n        cond_data = get_data(cond_table)\n        all_cond_data.append(cond_data)\n        \n    model = CGAN()\n    model.train(data, all_cond_data)\n    return model\n  \ndef train_per_entity_without_condition(table, data_models_per_entity): \n    data = get_data(table)\n    for entity in table['entities']:\n        entity_data = get_entity_data(data, entity)\n        model = GAN()\n        model.train(entity_data)\n        entity_signture = '_'.join([col['name'] for col in entity['columns']].sort())\n        data_models_per_entity[entity_signture] = model\n        \ndef train_per_entity_with_condition(schema_discovery, table_name, col_name, data_models_per_entity, table_dep_dict):\n    all_cond_data = []\n    table = get_table_by_name(schema_discovery, table_name)\n    data = get_data(table)\n    for cond_table_name in table_dep_dict[(table_name, col_name)]:\n        cond_table = get_table_by_name(schema_discovery, cond_table_name)\n        cond_data = get_train_data(cond_table)\n        all_cond_data.append(cond_data)\n    for entity in table['entities']:\n        entity_data = get_entity_data(data, entity)\n        model = CGAN()\n        model.train(entity_data, all_cond_data)\n        entity_signture = '_'.join([col['name'] for col in entity['columns']].sort())\n        data_models_per_entity[entity_signture] = model\n        \n        \ndef train_per_table(schema_discovery, in_degree_dict, table_dep_dict):\n    data_models_per_table = {}\n    for table_name, col_name in in_degree_dict:\n        condition_flag = False\n        if in_degree_dict[(table,name, col_name)] == 0:\n            table = get_table_by_name(schema_discovery, table_name)\n            model = train_without_condition(table)       \n                \n        else:\n            model = train_with_condition(schema_discovery, table_name, col_name, table_dep_dict)\n            condition_flag = True\n        \n        data_models_per_table[table_name] = {'model': model, 'condition_flag': condition_flag}\n        \n    for table in schema_discovery['tables']:\n        if table['name'] not in data_models_per_table:\n            model = train_without_condition(table)\n            data_models_per_table[table_name] = {'model': model, 'condition_flag': False}\n            \n    return data_models_per_table\n\n  \ndef predict_per_table(schema_discovery, data_models_per_table, table_dep_dict):\n    predicted_data_per_table = {}\n    for table_name in data_models_per_table:\n        if not data_models_per_table[table_name]['condition_flag']:         \n            model = data_models_per_table[table_name]\n            predicted_data = model.predict()\n            predicted_data_per_table[table_name] = predicted_data\n        else:\n            cond_data = []\n            for cond_table_name in table_dep_dict[(table_name, col_name)]:\n                cond_table = get_table_by_name(schema_discovery, cond_table_name)\n                cond_data = get_data(cond_table)\n                all_cond_data.append(cond_data)\n            \n          \n# in_degree_dict, table_dep_dict  = sort_table_by_degree(schema_discovery)\n# data_models_per_table = train_per_table(schema_discovery, in_degree_dict, table_dep_dict)\n# predicted_data_per_table = predict_per_table(schema_discovery, data_models_per_table, table_dep_dict)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["in_degree_dict, table_dep_dict = sort_table_by_degree(schema_discovery)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["in_degree_dict"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[19]: {(&#39;credit_card_balance&#39;, &#39;SK_ID_PREV&#39;): 1,\n (&#39;bureau&#39;, &#39;SK_ID_BUREAU&#39;): 1,\n (&#39;bureau2&#39;, &#39;SK_ID_BUREAU&#39;): 1,\n (&#39;pos_cash_balance&#39;, &#39;SK_ID_PREV&#39;): 1,\n (&#39;installments_payments&#39;, &#39;SK_ID_PREV&#39;): 1,\n (&#39;application_test2&#39;, &#39;SK_ID_CURR&#39;): 2,\n (&#39;credit_card_balance&#39;, &#39;SK_ID_CURR&#39;): 3,\n (&#39;previous_application&#39;, &#39;SK_ID_PREV&#39;): 3,\n (&#39;bureau&#39;, &#39;SK_ID_CURR&#39;): 3,\n (&#39;bureau2&#39;, &#39;SK_ID_CURR&#39;): 3,\n (&#39;pos_cash_balance&#39;, &#39;SK_ID_CURR&#39;): 3,\n (&#39;installments_payments&#39;, &#39;SK_ID_CURR&#39;): 3,\n (&#39;previous_application&#39;, &#39;SK_ID_CURR&#39;): 3,\n (&#39;application_train&#39;, &#39;SK_ID_CURR&#39;): 6,\n (&#39;sample_submission&#39;, &#39;SK_ID_CURR&#39;): 8,\n (&#39;application_test&#39;, &#39;SK_ID_CURR&#39;): 8}</div>"]}}],"execution_count":7},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":8}],"metadata":{"name":"train_predict","notebookId":3788284435573684},"nbformat":4,"nbformat_minor":0}
